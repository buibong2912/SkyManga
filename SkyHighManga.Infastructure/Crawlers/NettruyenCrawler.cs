using SkyHighManga.Infastructure.Data;
using System.Collections.Concurrent;
using System.Threading;
using SkyHighManga.Application.Common;
using SkyHighManga.Application.Common.Models;
using SkyHighManga.Application.Interfaces.Crawlers;
using SkyHighManga.Application.Interfaces.Services;
using SkyHighManga.Domain.Entities;

namespace SkyHighManga.Infastructure.Crawlers;

/// <summary>
/// Crawler cho Nettruyen (aquastarsleep.co.uk)
/// </summary>
public class NettruyenCrawler : BaseCrawler, IMangaCrawler, IChapterCrawler, IPageCrawler
{
    private readonly IHtmlParser _htmlParser;

    public NettruyenCrawler(
        IHtmlParser htmlParser,
        IRateLimiter? rateLimiter = null,
        Func<HttpClient>? httpClientFactory = null)
        : base(rateLimiter, httpClientFactory)
    {
        _htmlParser = htmlParser;
    }

    public override string Name => "NettruyenCrawler";

    public override SourceType SupportedSourceType => SourceType.Website;

    public override bool CanCrawl(Source source)
    {
        return base.CanCrawl(source) &&
               (source.BaseUrl.Contains("aquastarsleep.co.uk") ||
                source.BaseUrl.Contains("nettruyen"));
    }

    public async Task<CrawlerListResult<MangaCrawlData>> CrawlMangaListAsync(
        CrawlerContext context,
        int? maxItems = null)
    {
        try
        {
            Log(context, $"B·∫Øt ƒë·∫ßu crawl danh s√°ch manga t·ª´: {context.StartUrl}", Application.Common.Models.LogLevel.Info);

            var html = await DownloadHtmlAsync(context.StartUrl, context.CancellationToken);
            var document = _htmlParser.Parse(html);

            // T√¨m t·∫•t c·∫£ c√°c m-post items (class c√≥ th·ªÉ l√† "m-post col-md-6" ho·∫∑c ch·ªâ "m-post")
            var mangaItems = document.QuerySelectorAll("//div[contains(@class, 'm-post')]").ToList();

            var results = new List<MangaCrawlData>();
            var totalCount = mangaItems.Count;
            var max = maxItems ?? totalCount;

            Log(context, $"T√¨m th·∫•y {totalCount} manga items, s·∫Ω crawl {max} items", Application.Common.Models.LogLevel.Info);

            for (int i = 0; i < Math.Min(max, totalCount); i++)
            {
                if (context.CancellationToken.IsCancellationRequested)
                    break;

                var item = mangaItems[i];
                var mangaData = ParseMangaItem(item, context.Source.BaseUrl);

                if (mangaData != null)
                {
                    results.Add(mangaData);
                    UpdateProgress(context, i + 1, max);
                }
            }

            Log(context, $"Ho√†n th√†nh crawl {results.Count} manga", Application.Common.Models.LogLevel.Info);

            return CrawlerListResult<MangaCrawlData>.Success(results, results.Count, context.StartUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl danh s√°ch manga: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<MangaCrawlData>.Failure(
                $"L·ªói khi crawl danh s√°ch manga: {ex.Message}",
                ex,
                context.StartUrl);
        }
    }

    public async Task<CrawlerResult<MangaCrawlData>> CrawlMangaAsync(
        string mangaUrl,
        CrawlerContext context)
    {
        try
        {
            Log(context, $"B·∫Øt ƒë·∫ßu crawl manga t·ª´: {mangaUrl}", Application.Common.Models.LogLevel.Info);

            var fullUrl = BuildFullUrl(context.Source.BaseUrl, mangaUrl);
            var html = await DownloadHtmlAsync(fullUrl, context.CancellationToken);
            var document = _htmlParser.Parse(html);

            var mangaData = ParseMangaDetailPage(document, fullUrl);

            if (mangaData == null)
            {
                return CrawlerResult<MangaCrawlData>.Failure(
                    "Kh√¥ng th·ªÉ parse th√¥ng tin manga",
                    null,
                    fullUrl);
            }

            Log(context, $"Ho√†n th√†nh crawl manga: {mangaData.Title}", Application.Common.Models.LogLevel.Info);

            return CrawlerResult<MangaCrawlData>.Success(mangaData, fullUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl manga: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerResult<MangaCrawlData>.Failure(
                $"L·ªói khi crawl manga: {ex.Message}",
                ex,
                mangaUrl);
        }
    }

    public async Task<CrawlerResult<MangaCrawlData>> CrawlMangaDetailsAsync(
        string mangaUrl,
        CrawlerContext context)
    {
        // T∆∞∆°ng t·ª± CrawlMangaAsync nh∆∞ng ch·ªâ l·∫•y th√¥ng tin chi ti·∫øt, kh√¥ng crawl chapters
        return await CrawlMangaAsync(mangaUrl, context);
    }

    public async Task<CrawlerListResult<MangaCrawlData>> SearchMangaAsync(
        string keyword,
        CrawlerContext context,
        int? maxResults = null,
        int? maxPages = null)
    {
        try
        {

            var baseSearchUrl = $"{context.Source.BaseUrl}/tim-kiem";
            if (!string.IsNullOrWhiteSpace(keyword))
            {
                baseSearchUrl = $"{context.Source.BaseUrl}/tim-kiem?keyword={Uri.EscapeDataString(keyword)}";

            }
            Log(context, $"T√¨m ki·∫øm manga v·ªõi keyword: {keyword}", Application.Common.Models.LogLevel.Info);
            Log(context, $"Base Search URL: {baseSearchUrl}", Application.Common.Models.LogLevel.Debug);

            var allResults = new ConcurrentBag<MangaCrawlData>();
            int totalPages = 1;
            int pagesToCrawl = 1; // Default, s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t sau khi parse totalPages

            // Crawl trang ƒë·∫ßu ti√™n ƒë·ªÉ l·∫•y th√¥ng tin pagination
            var firstPageUrl = baseSearchUrl;
            var html = await DownloadHtmlAsync(firstPageUrl, context.CancellationToken);
            var document = _htmlParser.Parse(html);

            // Parse t·ªïng s·ªë trang t·ª´ pagination element
            var paginationElement = document.QuerySelector("//ul[@class='pagination']");
            if (paginationElement != null)
            {
                var countPageAttr = paginationElement.GetAttribute("data-count-page");
                if (!string.IsNullOrEmpty(countPageAttr) && int.TryParse(countPageAttr, out var countPage))
                {
                    totalPages = countPage;
                    Log(context, $"‚úÖ T√¨m th·∫•y {totalPages} trang k·∫øt qu·∫£ t·ª´ pagination", Application.Common.Models.LogLevel.Info);
                }
                else
                {
                    Log(context, $"‚ö†Ô∏è Kh√¥ng th·ªÉ parse data-count-page t·ª´ pagination. Attribute value: '{countPageAttr}'", Application.Common.Models.LogLevel.Warning);
                }
            }
            else
            {
                Log(context, "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y pagination element (ul[@class='pagination']). C√≥ th·ªÉ ch·ªâ c√≥ 1 trang ho·∫∑c HTML structure kh√°c.", Application.Common.Models.LogLevel.Warning);
            }
            
            // N·∫øu maxPages = null v√† totalPages = 1, c√≥ th·ªÉ c·∫ßn crawl th√™m ƒë·ªÉ ki·ªÉm tra
            // Nh∆∞ng tr∆∞·ªõc ti√™n, log ƒë·ªÉ debug
            if (maxPages == null && totalPages == 1)
            {
                Log(context, "‚ö†Ô∏è maxPages = null nh∆∞ng totalPages = 1. C√≥ th·ªÉ ch·ªâ c√≥ 1 trang ho·∫∑c pagination ch∆∞a ƒë∆∞·ª£c parse ƒë√∫ng.", Application.Common.Models.LogLevel.Warning);
            }

            // X√°c ƒë·ªãnh s·ªë trang c·∫ßn crawl
            if (maxPages == null)
            {
                // maxPages = null nghƒ©a l√† crawl T·∫§T C·∫¢ c√°c trang (t·∫•t c·∫£ pages c·ªßa truy·ªán)
                pagesToCrawl = totalPages;
                if (totalPages > 1)
                {
                    Log(context, $"‚úÖ maxPages = null ‚Üí s·∫Ω crawl T·∫§T C·∫¢ {totalPages} trang (t·∫•t c·∫£ pages c·ªßa truy·ªán)", Application.Common.Models.LogLevel.Info);
                }
                else
                {
                    Log(context, $"‚ö†Ô∏è maxPages = null nh∆∞ng ch·ªâ c√≥ {totalPages} trang. C√≥ th·ªÉ pagination ch∆∞a ƒë∆∞·ª£c parse ƒë√∫ng ho·∫∑c th·ª±c s·ª± ch·ªâ c√≥ 1 trang.", Application.Common.Models.LogLevel.Warning);
                    Log(context, $"S·∫Ω crawl {pagesToCrawl} trang (c√≥ th·ªÉ c·∫ßn ki·ªÉm tra l·∫°i pagination parsing)", Application.Common.Models.LogLevel.Info);
                }
            }
            else if (maxPages <= 0)
            {
                // maxPages <= 0 nghƒ©a l√† crawl t·∫•t c·∫£ c√°c trang (backward compatibility)
                pagesToCrawl = totalPages;
                Log(context, $"maxPages <= 0 ‚Üí s·∫Ω crawl T·∫§T C·∫¢ {totalPages} trang", Application.Common.Models.LogLevel.Info);
            }
            else
            {
                // maxPages > 0 nghƒ©a l√† crawl t·ªëi ƒëa maxPages trang
                pagesToCrawl = Math.Min(maxPages.Value, totalPages);
                Log(context, $"maxPages = {maxPages} ‚Üí s·∫Ω crawl t·ªëi ƒëa {pagesToCrawl} trang (t·ªïng {totalPages} trang)", Application.Common.Models.LogLevel.Info);
            }

            Log(context, $"üöÄ B·∫Øt ƒë·∫ßu crawl {pagesToCrawl} trang song song...", Application.Common.Models.LogLevel.Info);

            var seenUrls = new ConcurrentDictionary<string, bool>(StringComparer.OrdinalIgnoreCase);
            
            var estimatedTotalItems = pagesToCrawl * 10;
            var totalItemsTarget = maxResults ?? estimatedTotalItems;

            // T·ªëi ∆∞u: Crawl nhi·ªÅu pages song song v·ªõi multi-threading
            // TƒÉng concurrency l√™n cao h∆°n ƒë·ªÉ crawl nhanh h∆°n (ƒë·∫∑c bi·ªát khi c√≥ nhi·ªÅu pages)
            int maxConcurrency = pagesToCrawl > 100 ? 50 : (pagesToCrawl > 20 ? 20 : 10); // TƒÉng concurrency khi c√≥ nhi·ªÅu pages
            Log(context, $"‚öôÔ∏è S·ª≠ d·ª•ng concurrency: {maxConcurrency} pages ƒë·ªìng th·ªùi", Application.Common.Models.LogLevel.Info);
            var semaphore = new SemaphoreSlim(maxConcurrency, maxConcurrency);
            var failedPages = new ConcurrentBag<int>();
            const int maxRetries = 3;
            var processedPages = 0;

            // X·ª≠ l√Ω trang ƒë·∫ßu ti√™n (ƒë√£ c√≥ document)
            if (pagesToCrawl >= 1)
            {
                var firstPageResults = await CrawlPageAsync(1, baseSearchUrl, document, context, seenUrls, baseSearchUrl, 3);
                foreach (var mangaData in firstPageResults)
                {
                    if (maxResults.HasValue && allResults.Count >= maxResults.Value)
                        break;
                    allResults.Add(mangaData);
                }
                Interlocked.Increment(ref processedPages);
                UpdateProgress(context, allResults.Count, totalItemsTarget);
            }

            // Crawl c√°c trang c√≤n l·∫°i song song
            if (pagesToCrawl > 1)
            {
                Log(context, $"üì• B·∫Øt ƒë·∫ßu crawl {pagesToCrawl - 1} trang c√≤n l·∫°i (t·ª´ trang 2 ƒë·∫øn trang {pagesToCrawl})...", Application.Common.Models.LogLevel.Info);
                
                // V·ªõi s·ªë l∆∞·ª£ng pages l·ªõn, s·ª≠ d·ª•ng batch processing ƒë·ªÉ tr√°nh t·∫°o qu√° nhi·ªÅu tasks c√πng l√∫c
                const int batchSize = 200; // X·ª≠ l√Ω 200 pages m·ªói batch
                var totalPagesToCrawl = pagesToCrawl - 1; // Tr·ª´ trang ƒë·∫ßu ti√™n
                var totalBatches = (int)Math.Ceiling(totalPagesToCrawl / (double)batchSize);
                
                var lastProgressLog = DateTime.UtcNow;
                const int progressLogIntervalSeconds = 10; // Log progress m·ªói 10 gi√¢y
                var totalProcessed = 0;
                
                for (int batchIndex = 0; batchIndex < totalBatches; batchIndex++)
                {
                    if (context.CancellationToken.IsCancellationRequested)
                        break;

                    var startPage = 2 + (batchIndex * batchSize);
                    var endPage = Math.Min(startPage + batchSize - 1, pagesToCrawl);
                    var batchPages = endPage - startPage + 1;
                    
                    Log(context, $"üì¶ Batch {batchIndex + 1}/{totalBatches}: Crawl pages {startPage}-{endPage} ({batchPages} pages)...", 
                        Application.Common.Models.LogLevel.Info);
                    
                    var batchTasks = new List<Task>();
                    
                    for (int page = startPage; page <= endPage; page++)
                    {
                        if (context.CancellationToken.IsCancellationRequested)
                            break;

                        // Ki·ªÉm tra n·∫øu ƒë√£ ƒë·ªß maxResults
                        if (maxResults.HasValue && allResults.Count >= maxResults.Value)
                        {
                            Log(context, $"ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {maxResults.Value} k·∫øt qu·∫£", Application.Common.Models.LogLevel.Info);
                            break;
                        }

                        var pageNum = page; // Capture ƒë·ªÉ tr√°nh closure issue
                        var task = CrawlPageInParallelAsync(
                            pageNum, 
                            baseSearchUrl, 
                            context, 
                            seenUrls, 
                            allResults,
                            semaphore,
                            failedPages,
                            maxRetries,
                            maxResults,
                            totalItemsTarget,
                            pagesToCrawl);
                        
                        batchTasks.Add(task);
                    }

                    // ƒê·ª£i batch n√†y ho√†n th√†nh tr∆∞·ªõc khi chuy·ªÉn sang batch ti·∫øp theo
                    await Task.WhenAll(batchTasks);
                    
                    totalProcessed += batchTasks.Count;
                    var percent = (totalProcessed * 100.0) / totalPagesToCrawl;
                    
                    // Progress logging
                    if ((DateTime.UtcNow - lastProgressLog).TotalSeconds >= progressLogIntervalSeconds || batchIndex == totalBatches - 1)
                    {
                        Log(context, $"üìä Progress: ƒê√£ crawl {totalProcessed}/{totalPagesToCrawl} pages ({percent:F1}%), ƒê√£ t√¨m th·∫•y: {allResults.Count} mangas", 
                            Application.Common.Models.LogLevel.Info);
                        lastProgressLog = DateTime.UtcNow;
                    }
                }

                Log(context, $"‚úÖ ƒê√£ ho√†n th√†nh crawl {pagesToCrawl} trang. T·ªïng c·ªông {allResults.Count} mangas t√¨m ƒë∆∞·ª£c.", Application.Common.Models.LogLevel.Info);
            }
            else if (pagesToCrawl == 1)
            {
                Log(context, $"‚ÑπÔ∏è Ch·ªâ crawl 1 trang (totalPages = {totalPages}). T·ªïng c·ªông {allResults.Count} mangas t√¨m ƒë∆∞·ª£c.", Application.Common.Models.LogLevel.Info);
                if (maxPages == null)
                {
                    Log(context, "‚ö†Ô∏è L∆ØU √ù: maxPages = null nh∆∞ng ch·ªâ crawl ƒë∆∞·ª£c 1 trang. C√≥ th·ªÉ:", Application.Common.Models.LogLevel.Warning);
                    Log(context, "   1. Pagination element kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y ho·∫∑c parse kh√¥ng ƒë√∫ng", Application.Common.Models.LogLevel.Warning);
                    Log(context, "   2. Th·ª±c s·ª± ch·ªâ c√≥ 1 trang k·∫øt qu·∫£", Application.Common.Models.LogLevel.Warning);
                    Log(context, "   ‚Üí Ki·ªÉm tra logs ph√≠a tr√™n ƒë·ªÉ xem pagination c√≥ ƒë∆∞·ª£c parse ƒë√∫ng kh√¥ng", Application.Common.Models.LogLevel.Warning);
                }
            }
            else if (pagesToCrawl == 1)
            {
                Log(context, $"‚ÑπÔ∏è Ch·ªâ crawl 1 trang (totalPages = {totalPages}). T·ªïng c·ªông {allResults.Count} mangas t√¨m ƒë∆∞·ª£c.", Application.Common.Models.LogLevel.Info);
            }

            if (failedPages.Count > 0)
            {
                Log(context, $"C·∫£nh b√°o: {failedPages.Count} trang b·ªã l·ªói trong qu√° tr√¨nh crawl", Application.Common.Models.LogLevel.Warning);
            }
          

            // Gi·ªõi h·∫°n k·∫øt qu·∫£ theo maxResults n·∫øu c√≥
            var finalResults = allResults.ToList();
            if (maxResults.HasValue && finalResults.Count > maxResults.Value)
            {
                finalResults = finalResults.Take(maxResults.Value).ToList();
            }

            Log(context, $"Ho√†n th√†nh t√¨m ki·∫øm: {finalResults.Count} k·∫øt qu·∫£ t·ª´ {pagesToCrawl} trang", Application.Common.Models.LogLevel.Info);

            return CrawlerListResult<MangaCrawlData>.Success(finalResults, finalResults.Count, baseSearchUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi t√¨m ki·∫øm manga: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<MangaCrawlData>.Failure(
                $"L·ªói khi t√¨m ki·∫øm manga: {ex.Message}",
                ex,
                context.StartUrl);
        }
    }


    /// <summary>
    /// Crawl m·ªôt page v√† tr·∫£ v·ªÅ danh s√°ch manga items (cho trang ƒë·∫ßu ti√™n ƒë√£ c√≥ document)
    /// </summary>
    private async Task<List<MangaCrawlData>> CrawlPageAsync(
        int page,
        string baseSearchUrl,
        IHtmlDocument document,
        CrawlerContext context,
        ConcurrentDictionary<string, bool> seenUrls,
        string baseUrl, int maxRetries)
    {
        var results = new List<MangaCrawlData>();
        
        try
        {
            // Parse manga items t·ª´ trang n√†y
            var mangaItems = document.QuerySelectorAll("//div[@class='search-result']//div[contains(@class, 'm-post')]").ToList();
            if (mangaItems.Count == 0)
            {
                mangaItems = document.QuerySelectorAll("//div[contains(@class, 'm-post')]").ToList();
            }

            foreach (var item in mangaItems)
            {
                if (context.CancellationToken.IsCancellationRequested)
                    break;

                try
                {
                    var mangaData = ParseMangaItem(item, baseUrl);
                    if (mangaData != null && !string.IsNullOrEmpty(mangaData.SourceUrl))
                    {
                        if (seenUrls.TryAdd(mangaData.SourceUrl, true))
                        {
                            results.Add(mangaData);
                        }
                    }
                }
                catch (Exception ex)
                {
                    Log(context, $"L·ªói khi parse manga item ·ªü trang {page}: {ex.Message}", Application.Common.Models.LogLevel.Warning);
                }
            }

            Log(context, $"Trang {page}: T√¨m th·∫•y {results.Count} manga items m·ªõi", Application.Common.Models.LogLevel.Info);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl trang {page}: {ex.Message}", Application.Common.Models.LogLevel.Warning);
        }

        return results;
    }

    /// <summary>
    /// Crawl m·ªôt page song song v·ªõi c√°c pages kh√°c (cho c√°c trang t·ª´ 2 tr·ªü ƒëi)
    /// </summary>
    private async Task CrawlPageInParallelAsync(
        int page,
        string baseSearchUrl,
        CrawlerContext context,
        ConcurrentDictionary<string, bool> seenUrls,
        ConcurrentBag<MangaCrawlData> allResults,
        SemaphoreSlim semaphore,
        ConcurrentBag<int> failedPages,
        int maxRetries,
        int? maxResults,
        int totalItemsTarget,
        int pagesToCrawl)
    {
        await semaphore.WaitAsync(context.CancellationToken);
        
        try
        {
            // Ki·ªÉm tra n·∫øu ƒë√£ ƒë·ªß maxResults
            if (maxResults.HasValue && allResults.Count >= maxResults.Value)
            {
                return;
            }

            // Build URL cho trang n√†y
            var separator = baseSearchUrl.Contains('?') ? "&" : "?";
            var pageUrl = $"{baseSearchUrl}{separator}page={page}";

            // Retry logic
            bool pageSuccess = false;
            int retryCount = 0;
            List<IHtmlElement>? mangaItems = null;

            while (!pageSuccess && retryCount < 3)
            {
                try
                {
                    var html = await DownloadHtmlAsync(pageUrl, context.CancellationToken);
                    var document = _htmlParser.Parse(html);

                    // Parse manga items
                    mangaItems = document.QuerySelectorAll("//div[@class='search-result']//div[contains(@class, 'm-post')]").ToList();
                    if (mangaItems.Count == 0)
                    {
                        mangaItems = document.QuerySelectorAll("//div[contains(@class, 'm-post')]").ToList();
                    }
                    pageSuccess = true;
                }
                catch (Exception ex)
                {
                    retryCount++;
                    if (retryCount < 3)
                    {
                        Log(context, $"L·ªói khi crawl trang {page}, retry {retryCount}/{3}: {ex.Message}", Application.Common.Models.LogLevel.Warning);
                        await Task.Delay(2000 * retryCount, context.CancellationToken);
                    }
                    else
                    {
                        Log(context, $"L·ªói khi crawl trang {page} sau {3} l·∫ßn th·ª≠: {ex.Message}", Application.Common.Models.LogLevel.Error);
                        failedPages.Add(page);
                    }
                }
            }

            if (!pageSuccess || mangaItems == null)
            {
                Log(context, $"Trang {page}: Kh√¥ng th·ªÉ crawl ho·∫∑c kh√¥ng t√¨m th·∫•y items", Application.Common.Models.LogLevel.Warning);
                return;
            }

            // Parse t·ª´ng manga item
            int itemsAddedThisPage = 0;
            foreach (var item in mangaItems)
            {
                if (context.CancellationToken.IsCancellationRequested)
                    break;

                if (maxResults.HasValue && allResults.Count >= maxResults.Value)
                    break;

                try
                {
                    var mangaData = ParseMangaItem(item, context.Source.BaseUrl);
                    if (mangaData != null && !string.IsNullOrEmpty(mangaData.SourceUrl))
                    {
                        if (seenUrls.TryAdd(mangaData.SourceUrl, true))
                        {
                            allResults.Add(mangaData);
                            itemsAddedThisPage++;
                        }
                    }
                }
                catch (Exception ex)
                {
                    Log(context, $"L·ªói khi parse manga item ·ªü trang {page}: {ex.Message}", Application.Common.Models.LogLevel.Warning);
                }
            }

            // Log progress
            if (page % 10 == 0)
            {
                var progressPercent = pagesToCrawl > 0 ? (allResults.Count * 100.0 / (pagesToCrawl * 10)) : 0;
                Log(context, $"Progress: {allResults.Count}/{pagesToCrawl} trang ({progressPercent:F1}%) - {allResults.Count} items ƒë√£ crawl", Application.Common.Models.LogLevel.Info);
            }
            else
            {
                Log(context, $"Trang {page}: T√¨m th·∫•y {itemsAddedThisPage} manga items m·ªõi (t·ªïng: {allResults.Count})", Application.Common.Models.LogLevel.Debug);
            }

            // Update progress
            if (itemsAddedThisPage > 0)
            {
                UpdateProgress(context, allResults.Count, totalItemsTarget);
            }
        }
        finally
        {
            semaphore.Release();
        }
    }

    /// <summary>
    /// Parse m·ªôt manga item t·ª´ search result ho·∫∑c list page
    /// </summary>
    private MangaCrawlData? ParseMangaItem(IHtmlElement item, string baseUrl)
    {
        try
        {
            var mangaData = new MangaCrawlData();

            // L·∫•y title v√† URL - s·ª≠ d·ª•ng relative path (b·∫Øt ƒë·∫ßu v·ªõi .//) ƒë·ªÉ t√¨m trong item hi·ªán t·∫°i
            var titleElement = item.QuerySelector(".//h3[contains(@class, 'm-name')]//a");
            if (titleElement != null)
            {
                mangaData.Title = titleElement.TextContent?.Trim() ?? "";
                var href = titleElement.GetAttribute("href") ?? "";
                mangaData.SourceUrl = BuildFullUrl(baseUrl, href);
                
                // Extract SourceMangaId t·ª´ URL
                mangaData.SourceMangaId = ExtractMangaIdFromUrl(mangaData.SourceUrl);
            }

            // L·∫•y cover image - s·ª≠ d·ª•ng relative path
            var imgElement = item.QuerySelector(".//img[contains(@class, 'lzl')]");
            if (imgElement != null)
            {
                // ∆Øu ti√™n data-src, sau ƒë√≥ data-original, cu·ªëi c√πng l√† src
                mangaData.CoverImageUrl = imgElement.GetAttribute("data-src") 
                    ?? imgElement.GetAttribute("data-original")
                    ?? imgElement.GetAttribute("src");
                
                if (!string.IsNullOrEmpty(mangaData.CoverImageUrl) && !mangaData.CoverImageUrl.StartsWith("http"))
                {
                    mangaData.CoverImageUrl = BuildFullUrl(baseUrl, mangaData.CoverImageUrl);
                }
            }

            // L·∫•y rating - rating n·∫±m trong span con tr·ª±c ti·∫øp c·ªßa div.m-star (kh√¥ng c√≥ class)
            // C·∫•u tr√∫c: <div class="m-star"><span class="star-rating">...</span><span>4.2</span></div>
            // S·ª≠ d·ª•ng relative path
            var mStarDiv = item.QuerySelector(".//div[contains(@class, 'm-star')]");
            if (mStarDiv != null)
            {
                var allSpans = mStarDiv.QuerySelectorAll("./span").ToList();
                // T√¨m span kh√¥ng c√≥ class attribute (rating span)
                var ratingSpan = allSpans.FirstOrDefault(s => string.IsNullOrEmpty(s.GetAttribute("class")));
                
                if (ratingSpan != null)
                {
                    var ratingText = ratingSpan.TextContent?.Trim();
                    if (!string.IsNullOrEmpty(ratingText) && double.TryParse(ratingText, out var rating))
                    {
                        mangaData.Rating = rating;
                    }
                }
            }

            // L·∫•y view count - s·ª≠ d·ª•ng relative path
            var viewElement = item.QuerySelector(".//span[contains(@class, 'num-view')]");
            if (viewElement != null)
            {
                var viewText = viewElement.TextContent?.Trim() ?? "";
                mangaData.ViewCount = ParseViewCount(viewText);
            }

            // L·∫•y chapters - s·ª≠ d·ª•ng relative path
            var chapterElements = item.QuerySelectorAll(".//ul[contains(@class, 'list-chaps')]//li[contains(@class, 'chapter')]//a").ToList();
            foreach (var chapterElement in chapterElements)
            {
                var chapterUrl = chapterElement.GetAttribute("href");
                if (!string.IsNullOrEmpty(chapterUrl))
                {
                    var chapterData = new ChapterCrawlData
                    {
                        SourceUrl = BuildFullUrl(baseUrl, chapterUrl),
                        Title = chapterElement.TextContent?.Trim() ?? ""
                    };

                    // Extract chapter number t·ª´ title
                    var chapterMatch = System.Text.RegularExpressions.Regex.Match(
                        chapterData.Title, 
                        @"Chapter\s*#?(\d+)",
                        System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                    
                    if (chapterMatch.Success && int.TryParse(chapterMatch.Groups[1].Value, out var chapterNum))
                    {
                        chapterData.ChapterNumber = chapterMatch.Groups[1].Value;
                        chapterData.ChapterIndex = chapterNum;
                        // Set SourceChapterId t·ª´ chapter number
                        if (string.IsNullOrEmpty(chapterData.SourceChapterId))
                        {
                            chapterData.SourceChapterId = chapterMatch.Groups[1].Value;
                        }
                    }
                    else
                    {
                        // Th·ª≠ extract t·ª´ URL
                        var urlMatch = System.Text.RegularExpressions.Regex.Match(
                            chapterUrl,
                            @"chapter[_-]?(\d+)",
                            System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                        if (urlMatch.Success)
                        {
                            chapterData.SourceChapterId = urlMatch.Groups[1].Value;
                            chapterData.ChapterNumber = urlMatch.Groups[1].Value;
                            if (int.TryParse(urlMatch.Groups[1].Value, out var idx))
                            {
                                chapterData.ChapterIndex = idx;
                            }
                        }
                        else
                        {
                            // Fallback: s·ª≠ d·ª•ng URL l√†m SourceChapterId
                            chapterData.SourceChapterId = chapterUrl.Trim('/').Split('/').LastOrDefault() ?? chapterUrl;
                        }
                    }

                    mangaData.Chapters.Add(chapterData);
                }
            }

            return mangaData;
        }
        catch
        {
            // Log error nh∆∞ng kh√¥ng throw, ch·ªâ return null
            return null;
        }
    }

    /// <summary>
    /// Parse manga detail page
    /// </summary>
    private MangaCrawlData? ParseMangaDetailPage(IHtmlDocument document, string url)
    {
        try
        {
            var mangaData = new MangaCrawlData
            {
                SourceUrl = url
            };

            // Extract SourceMangaId t·ª´ URL (v√≠ d·ª•: /truyen-tranh/one-piece -> "one-piece")
            mangaData.SourceMangaId = ExtractMangaIdFromUrl(url);

            // Th·ª≠ l·∫•y t·ª´ script tag n·∫øu c√≥ (mangaDetail.id) - ∆∞u ti√™n h∆°n URL
            var mangaDetailScript = document.QuerySelector("//script[contains(text(), 'mangaDetail')]");
            if (mangaDetailScript != null)
            {
                var scriptText = mangaDetailScript.TextContent ?? "";
                var idMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"""id""\s*:\s*(\d+)",
                    System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                if (idMatch.Success)
                {
                    mangaData.SourceMangaId = idMatch.Groups[1].Value;
                }
            }

            // L·∫•y title - <h1 class="title title-detail"><a>One Piece</a></h1>
            var titleElement = document.QuerySelector("//h1[contains(@class, 'title-detail')]//a")
                ?? document.QuerySelector("//h1[contains(@class, 'title-detail')]")
                ?? document.QuerySelector("//h1");
            if (titleElement != null)
            {
                mangaData.Title = titleElement.TextContent?.Trim() ?? "";
            }

            // L·∫•y rating - <div class="m-star"><span class="star-rating">...</span><span>5</span></div>
            var mStarDiv = document.QuerySelector("//div[contains(@class, 'm-star')]");
            if (mStarDiv != null)
            {
                var allSpans = mStarDiv.QuerySelectorAll("./span").ToList();
                var ratingSpan = allSpans.FirstOrDefault(s => string.IsNullOrEmpty(s.GetAttribute("class")));
                if (ratingSpan != null)
                {
                    var ratingText = ratingSpan.TextContent?.Trim();
                    if (!string.IsNullOrEmpty(ratingText) && double.TryParse(ratingText, out var rating))
                    {
                        mangaData.Rating = rating;
                    }
                }
            }

            // L·∫•y th·ªÉ lo·∫°i - <div class="kind"><span class="label">Th·ªÉ lo·∫°i: </span><a href="/the-loai/manga">Manga</a></div>
            var kindElement = document.QuerySelector("//div[contains(@class, 'kind')]//a");
            if (kindElement != null)
            {
                var kindText = kindElement.TextContent?.Trim();
                if (!string.IsNullOrEmpty(kindText))
                {
                    mangaData.Genres.Add(kindText);
                }
            }

            // L·∫•y tags/genres - <div class="m-tags"><span class="label">Tags:</span><a href="/genre/shounen">Shounen</a>...</div>
            var tagElements = document.QuerySelectorAll("//div[contains(@class, 'm-tags')]//a[contains(@href, '/genre/')]").ToList();
            foreach (var tagElement in tagElements)
            {
                var tagName = tagElement.TextContent?.Trim();
                if (!string.IsNullOrEmpty(tagName))
                {
                    mangaData.Genres.Add(tagName);
                }
            }

            // L·∫•y t√¨nh tr·∫°ng - <div class="status"><span>T√¨nh tr·∫°ng: </span><p>ƒêang ti·∫øn h√†nh</p></div>
            var statusElement = document.QuerySelector("//div[contains(@class, 'status')]//p");
            if (statusElement != null)
            {
                var statusText = statusElement.TextContent?.Trim();
            }

            // L·∫•y t√°c gi·∫£ - <div class="author"><span>T√°c gi·∫£: </span><p>Eiichiro Oda</p></div>
            var authorElement = document.QuerySelector("//div[contains(@class, 'author')]//p");
            if (authorElement != null)
            {
                var authorName = authorElement.TextContent?.Trim();
                if (!string.IsNullOrEmpty(authorName))
                {
                    mangaData.AuthorName = authorName;
                }
            }

            // L·∫•y l∆∞·ª£t xem - <div class="view"><span>L∆∞·ª£t xem: </span><p>80.172</p></div>
            var viewElement = document.QuerySelector("//div[contains(@class, 'view')]//p");
            if (viewElement != null)
            {
                var viewText = viewElement.TextContent?.Trim();
                if (!string.IsNullOrEmpty(viewText))
                {
                    // Parse s·ªë l∆∞·ª£t xem (c√≥ th·ªÉ c√≥ d·∫•u ch·∫•m nh∆∞ "80.172")
                    viewText = viewText.Replace(".", "");
                    if (int.TryParse(viewText, out var viewCount))
                    {
                        mangaData.ViewCount = viewCount;
                    }
                }
            }

            // L·∫•y description - <div class="sort-des"><h2>...</h2><div class="line-clamp html-content">...</div></div>
            var descElement = document.QuerySelector("//div[contains(@class, 'sort-des')]//div[contains(@class, 'html-content')]")
                ?? document.QuerySelector("//div[contains(@class, 'sort-des')]//div[contains(@class, 'line-clamp')]");
            if (descElement != null)
            {
                mangaData.Description = descElement.TextContent?.Trim();
            }

            // L·∫•y cover image - c√≥ th·ªÉ t·ª´ posterPath trong script tag ho·∫∑c t·ª´ img element
            // Th·ª≠ l·∫•y t·ª´ script tag tr∆∞·ªõc (mangaDetail.posterPath)
            var scriptElement = document.QuerySelector("//script[contains(text(), 'mangaDetail')]");
            if (scriptElement != null)
            {
                var scriptText = scriptElement.TextContent ?? "";
                var posterMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"posterPath[""']?\s*:\s*[""']([^""']+)",
                    System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                
                if (posterMatch.Success)
                {
                    mangaData.CoverImageUrl = posterMatch.Groups[1].Value;
                }
            }

            // N·∫øu kh√¥ng c√≥ t·ª´ script, th·ª≠ l·∫•y t·ª´ img element
            if (string.IsNullOrEmpty(mangaData.CoverImageUrl))
            {
                var coverImg = document.QuerySelector("//div[contains(@class, 'col-thumb')]//img")
                    ?? document.QuerySelector("//img[contains(@class, 'poster')]");
                if (coverImg != null)
                {
                    mangaData.CoverImageUrl = coverImg.GetAttribute("src")
                        ?? coverImg.GetAttribute("data-src")
                        ?? coverImg.GetAttribute("data-original");
                }
            }

            // L·∫•y danh s√°ch chapters - th·ª≠ nhi·ªÅu selector kh√°c nhau
            var chapterElements = document.QuerySelectorAll("//div[contains(@class, 'list-chapters')]//div[contains(@class, 'l-chapter')]//a[contains(@class, 'll-chap')]").ToList();
            
            // Fallback: th·ª≠ selector ƒë∆°n gi·∫£n h∆°n
            if (chapterElements.Count == 0)
            {
                chapterElements = document.QuerySelectorAll("//div[contains(@class, 'list-chapters')]//a[contains(@href, 'chapter')]").ToList();
            }
            
            // Fallback: th·ª≠ selector kh√°c
            if (chapterElements.Count == 0)
            {
                chapterElements = document.QuerySelectorAll("//div[contains(@class, 'list-chapters')]//a").ToList();
            }
            
            // Log ƒë·ªÉ debug
            if (chapterElements.Count == 0)
            {
                // Th·ª≠ t√¨m b·∫•t k·ª≥ link n√†o c√≥ ch·ª©a "chapter" trong href
                chapterElements = document.QuerySelectorAll("//a[contains(@href, 'chapter')]").ToList();
            }
            
            foreach (var chapterElement in chapterElements)
            {
                var chapterUrl = chapterElement.GetAttribute("href");
                if (!string.IsNullOrEmpty(chapterUrl))
                {
                    var chapterData = new ChapterCrawlData
                    {
                        SourceUrl = BuildFullUrl(url, chapterUrl),
                        Title = chapterElement.TextContent?.Trim() ?? ""
                    };

                    // Extract chapter number t·ª´ title ho·∫∑c URL
                    var chapterMatch = System.Text.RegularExpressions.Regex.Match(
                        chapterData.Title,
                        @"Chapter\s*#?(\d+)",
                        System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                    
                    if (!chapterMatch.Success)
                    {
                        // Th·ª≠ extract t·ª´ URL
                        chapterMatch = System.Text.RegularExpressions.Regex.Match(
                            chapterUrl,
                            @"chapter-(\d+)",
                            System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                    }

                    if (chapterMatch.Success && int.TryParse(chapterMatch.Groups[1].Value, out var chapterNum))
                    {
                        chapterData.ChapterNumber = chapterMatch.Groups[1].Value;
                        chapterData.ChapterIndex = chapterNum;
                        // Set SourceChapterId t·ª´ chapter number
                        if (string.IsNullOrEmpty(chapterData.SourceChapterId))
                        {
                            chapterData.SourceChapterId = chapterMatch.Groups[1].Value;
                        }
                    }
                    else
                    {
                        // Th·ª≠ extract t·ª´ URL v·ªõi pattern kh√°c
                        var urlMatch = System.Text.RegularExpressions.Regex.Match(
                            chapterUrl,
                            @"chapter[_-]?(\d+)",
                            System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                        if (urlMatch.Success)
                        {
                            chapterData.SourceChapterId = urlMatch.Groups[1].Value;
                            chapterData.ChapterNumber = urlMatch.Groups[1].Value;
                            if (int.TryParse(urlMatch.Groups[1].Value, out var idx))
                            {
                                chapterData.ChapterIndex = idx;
                            }
                        }
                        else
                        {
                            // Fallback: s·ª≠ d·ª•ng URL l√†m SourceChapterId
                            chapterData.SourceChapterId = chapterUrl.Trim('/').Split('/').LastOrDefault() ?? chapterUrl;
                        }
                    }

                    mangaData.Chapters.Add(chapterData);
                }
            }

            return mangaData;
        }
        catch
        {
            // Log error n·∫øu c√≥ context
            return null;
        }
    }

    /// <summary>
    /// Extract manga ID t·ª´ URL (v√≠ d·ª•: /truyen-tranh/one-piece -> "one-piece")
    /// </summary>
    private string? ExtractMangaIdFromUrl(string url)
    {
        if (string.IsNullOrEmpty(url))
            return null;

        try
        {
            // Pattern: /truyen-tranh/{manga-id} ho·∫∑c /truyen-tranh/{manga-id}/...
            var match = System.Text.RegularExpressions.Regex.Match(
                url,
                @"/truyen-tranh/([^/?#]+)",
                System.Text.RegularExpressions.RegexOptions.IgnoreCase);

            if (match.Success)
            {
                return match.Groups[1].Value;
            }

            // Fallback: l·∫•y ph·∫ßn cu·ªëi c·ªßa URL path
            var uri = new Uri(url);
            var segments = uri.Segments;
            for (int i = segments.Length - 1; i >= 0; i--)
            {
                var segment = segments[i].Trim('/');
                if (!string.IsNullOrEmpty(segment) && 
                    !segment.Equals("truyen-tranh", StringComparison.OrdinalIgnoreCase) &&
                    !segment.StartsWith("chapter", StringComparison.OrdinalIgnoreCase))
                {
                    return segment;
                }
            }
        }
        catch
        {
            // Ignore errors
        }

        return null;
    }

    /// <summary>
    /// Parse view count t·ª´ text (v√≠ d·ª•: "10.24M l∆∞·ª£t xem" -> 10240000)
    /// </summary>
    private int ParseViewCount(string viewText)
    {
        if (string.IsNullOrWhiteSpace(viewText))
            return 0;

        try
        {
            // Remove "l∆∞·ª£t xem" v√† trim
            viewText = viewText.Replace("l∆∞·ª£t xem", "").Trim();

            // Parse s·ªë v·ªõi K, M suffix
            var match = System.Text.RegularExpressions.Regex.Match(
                viewText,
                @"([\d.]+)\s*([KMkm]?)",
                System.Text.RegularExpressions.RegexOptions.IgnoreCase);

            if (match.Success && double.TryParse(match.Groups[1].Value, out var number))
            {
                var suffix = match.Groups[2].Value.ToUpper();
                return suffix switch
                {
                    "K" => (int)(number * 1000),
                    "M" => (int)(number * 1000000),
                    _ => (int)number
                };
            }
        }
        catch
        {
            // Ignore parse errors
        }

        return 0;
    }

    #region IChapterCrawler Implementation

    public async Task<CrawlerListResult<ChapterCrawlData>> CrawlChaptersAsync(
        string mangaUrl,
        CrawlerContext context,
        int? maxChapters = null)
    {
        try
        {
            Log(context, $"B·∫Øt ƒë·∫ßu crawl chapters t·ª´: {mangaUrl}", Application.Common.Models.LogLevel.Info);

            // Crawl manga detail ƒë·ªÉ l·∫•y danh s√°ch chapters
            var mangaResult = await CrawlMangaAsync(mangaUrl, context);
            if (!mangaResult.IsSuccess || mangaResult.Data == null)
            {
                return CrawlerListResult<ChapterCrawlData>.Failure(
                    "Kh√¥ng th·ªÉ crawl manga ƒë·ªÉ l·∫•y chapters",
                    mangaResult.Exception,
                    mangaUrl);
            }

            var chapters = mangaResult.Data.Chapters.ToList();
            var max = maxChapters ?? chapters.Count;

            Log(context, $"T√¨m th·∫•y {chapters.Count} chapters, s·∫Ω crawl {max} chapters", Application.Common.Models.LogLevel.Info);

            var results = chapters.Take(max).ToList();

            return CrawlerListResult<ChapterCrawlData>.Success(results, results.Count, mangaUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl chapters: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<ChapterCrawlData>.Failure(
                $"L·ªói khi crawl chapters: {ex.Message}",
                ex,
                mangaUrl);
        }
    }

    public async Task<CrawlerResult<ChapterCrawlData>> CrawlChapterAsync(
        string chapterUrl,
        CrawlerContext context)
    {
        try
        {
            Log(context, $"B·∫Øt ƒë·∫ßu crawl chapter t·ª´: {chapterUrl}", Application.Common.Models.LogLevel.Info);

            var fullUrl = BuildFullUrl(context.Source.BaseUrl, chapterUrl);
            var html = await DownloadHtmlAsync(fullUrl, context.CancellationToken);
            var document = _htmlParser.Parse(html);

            var chapterData = ParseChapterPage(document, fullUrl);

            if (chapterData == null)
            {
                return CrawlerResult<ChapterCrawlData>.Failure(
                    "Kh√¥ng th·ªÉ parse th√¥ng tin chapter",
                    null,
                    fullUrl);
            }

            Log(context, $"Ho√†n th√†nh crawl chapter: {chapterData.Title} ({chapterData.PageUrls.Count} pages)", Application.Common.Models.LogLevel.Info);

            return CrawlerResult<ChapterCrawlData>.Success(chapterData, fullUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl chapter: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerResult<ChapterCrawlData>.Failure(
                $"L·ªói khi crawl chapter: {ex.Message}",
                ex,
                chapterUrl);
        }
    }

    public async Task<CrawlerListResult<ChapterCrawlData>> CrawlNewChaptersAsync(
        string mangaUrl,
        IEnumerable<string> existingChapterIds,
        CrawlerContext context)
    {
        try
        {
            var existingIds = existingChapterIds.ToHashSet();
            var allChaptersResult = await CrawlChaptersAsync(mangaUrl, context);

            if (!allChaptersResult.IsSuccess || allChaptersResult.Data == null)
            {
                return allChaptersResult;
            }

            var newChapters = allChaptersResult.Data
                .Where(c => !existingIds.Contains(c.SourceChapterId ?? ""))
                .ToList();

            Log(context, $"T√¨m th·∫•y {newChapters.Count} chapters m·ªõi", Application.Common.Models.LogLevel.Info);

            return CrawlerListResult<ChapterCrawlData>.Success(newChapters, newChapters.Count, mangaUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl chapters m·ªõi: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<ChapterCrawlData>.Failure(
                $"L·ªói khi crawl chapters m·ªõi: {ex.Message}",
                ex,
                mangaUrl);
        }
    }

    /// <summary>
    /// Parse chapter page ƒë·ªÉ l·∫•y th√¥ng tin chapter v√† danh s√°ch image URLs
    /// </summary>
    private ChapterCrawlData? ParseChapterPage(IHtmlDocument document, string url)
    {
        try
        {
            var chapterData = new ChapterCrawlData
            {
                SourceUrl = url
            };

            // L·∫•y title t·ª´ script tag ho·∫∑c HTML
            var scriptElement = document.QuerySelector("//script[contains(text(), 'chapterDetail')]");
            if (scriptElement != null)
            {
                var scriptText = scriptElement.TextContent ?? "";
                
                // Parse chapterDetail JSON
                var nameMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"""name""\s*:\s*""([^""]+)""",
                    System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                if (nameMatch.Success)
                {
                    chapterData.Title = nameMatch.Groups[1].Value;
                }

                var indexMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"""index""\s*:\s*(\d+)",
                    System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                if (indexMatch.Success && int.TryParse(indexMatch.Groups[1].Value, out var index))
                {
                    chapterData.ChapterIndex = index;
                    chapterData.ChapterNumber = indexMatch.Groups[1].Value;
                }

                var idMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"""id""\s*:\s*(\d+)",
                    System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                if (idMatch.Success)
                {
                    chapterData.SourceChapterId = idMatch.Groups[1].Value;
                }

                // Parse images array t·ª´ script tag (∆∞u ti√™n)
                var imagesMatch = System.Text.RegularExpressions.Regex.Match(
                    scriptText,
                    @"""images""\s*:\s*\[(.*?)\]",
                    System.Text.RegularExpressions.RegexOptions.Singleline | System.Text.RegularExpressions.RegexOptions.IgnoreCase);
                
                if (imagesMatch.Success)
                {
                    var imagesJson = imagesMatch.Groups[1].Value;
                    
                    // Parse c·∫£ index v√† path ƒë·ªÉ sort ƒë√∫ng th·ª© t·ª±
                    var fullImageMatches = System.Text.RegularExpressions.Regex.Matches(
                        imagesJson,
                        @"""index""\s*:\s*(\d+).*?""path""\s*:\s*""([^""]+)""",
                        System.Text.RegularExpressions.RegexOptions.Singleline | System.Text.RegularExpressions.RegexOptions.IgnoreCase);

                    var imageList = new List<(int index, string path)>();

                    foreach (System.Text.RegularExpressions.Match match in fullImageMatches)
                    {
                        if (int.TryParse(match.Groups[1].Value, out var imgIndex))
                        {
                            imageList.Add((imgIndex, match.Groups[2].Value));
                        }
                    }

                    // Sort theo index v√† l·∫•y paths
                    chapterData.PageUrls = imageList
                        .OrderBy(x => x.index)
                        .Select(x => x.path)
                        .ToList();
                }
            }

            // N·∫øu kh√¥ng parse ƒë∆∞·ª£c t·ª´ script, th·ª≠ parse t·ª´ HTML img elements
            if (chapterData.PageUrls.Count == 0)
            {
                var imgElements = document.QuerySelectorAll("//div[@id='read-chaps']//img[contains(@class, 'reading-img')]").ToList();
                
                var imageList = new List<(int index, string url)>();
                
                foreach (var imgElement in imgElements)
                {
                    // L·∫•y data-indexr ƒë·ªÉ sort
                    var indexAttr = imgElement.GetAttribute("data-indexr");
                    var imageUrl = imgElement.GetAttribute("src")
                        ?? imgElement.GetAttribute("data-src")
                        ?? imgElement.GetAttribute("data-original");

                    if (!string.IsNullOrEmpty(imageUrl) && !imageUrl.Contains("/images/pre-load"))
                    {
                        if (int.TryParse(indexAttr, out var pageIndex))
                        {
                            imageList.Add((pageIndex, imageUrl));
                        }
                        else
                        {
                            imageList.Add((int.MaxValue, imageUrl)); // Add to end if no index
                        }
                    }
                }

                // Sort v√† extract URLs
                chapterData.PageUrls = imageList
                    .OrderBy(x => x.index)
                    .Select(x => x.url)
                    .ToList();
            }

            // N·∫øu v·∫´n kh√¥ng c√≥ title, th·ª≠ l·∫•y t·ª´ HTML
            if (string.IsNullOrEmpty(chapterData.Title))
            {
                var titleElement = document.QuerySelector("//h1[contains(@class, 'manga-name')]")
                    ?? document.QuerySelector("//h1");
                if (titleElement != null)
                {
                    chapterData.Title = titleElement.TextContent?.Trim() ?? "";
                }
            }

            return chapterData;
        }
        catch
        {
            return null;
        }
    }

    #endregion

    #region IPageCrawler Implementation

    public async Task<CrawlerListResult<string>> CrawlPageUrlsAsync(
        string chapterUrl,
        CrawlerContext context)
    {
        try
        {
            Log(context, $"B·∫Øt ƒë·∫ßu crawl page URLs t·ª´: {chapterUrl}", Application.Common.Models.LogLevel.Info);

            var chapterResult = await CrawlChapterAsync(chapterUrl, context);
            if (!chapterResult.IsSuccess || chapterResult.Data == null)
            {
                return CrawlerListResult<string>.Failure(
                    "Kh√¥ng th·ªÉ crawl chapter ƒë·ªÉ l·∫•y page URLs",
                    chapterResult.Exception,
                    chapterUrl);
            }

            var pageUrls = chapterResult.Data.PageUrls.ToList();

            Log(context, $"T√¨m th·∫•y {pageUrls.Count} page URLs", Application.Common.Models.LogLevel.Info);

            return CrawlerListResult<string>.Success(pageUrls, pageUrls.Count, chapterUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi crawl page URLs: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<string>.Failure(
                $"L·ªói khi crawl page URLs: {ex.Message}",
                ex,
                chapterUrl);
        }
    }

    public async Task<CrawlerResult<byte[]>> DownloadPageAsync(
        string imageUrl,
        CrawlerContext context)
    {
        try
        {
            Log(context, $"Downloading image: {imageUrl}", Application.Common.Models.LogLevel.Debug);

            var fullUrl = BuildFullUrl(context.Source.BaseUrl, imageUrl);
            var imageData = await DownloadBytesAsync(fullUrl, context.CancellationToken);

            return CrawlerResult<byte[]>.Success(imageData, fullUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi download image: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerResult<byte[]>.Failure(
                $"L·ªói khi download image: {ex.Message}",
                ex,
                imageUrl);
        }
    }

    public async Task<CrawlerListResult<byte[]>> DownloadPagesAsync(
        IEnumerable<string> imageUrls,
        CrawlerContext context,
        int? maxPages = null)
    {
        try
        {
            var urls = imageUrls.ToList();
            var max = maxPages ?? urls.Count;
            var results = new List<byte[]>();

            Log(context, $"B·∫Øt ƒë·∫ßu download {max} pages", Application.Common.Models.LogLevel.Info);

            for (int i = 0; i < Math.Min(max, urls.Count); i++)
            {
                if (context.CancellationToken.IsCancellationRequested)
                    break;

                var url = urls[i];
                var result = await DownloadPageAsync(url, context);

                if (result.IsSuccess && result.Data != null)
                {
                    results.Add(result.Data);
                    UpdateProgress(context, i + 1, max);
                }
            }

            Log(context, $"Ho√†n th√†nh download {results.Count} pages", Application.Common.Models.LogLevel.Info);

            return CrawlerListResult<byte[]>.Success(results, results.Count, context.StartUrl);
        }
        catch (Exception ex)
        {
            Log(context, $"L·ªói khi download pages: {ex.Message}", Application.Common.Models.LogLevel.Error);
            return CrawlerListResult<byte[]>.Failure(
                $"L·ªói khi download pages: {ex.Message}",
                ex,
                context.StartUrl);
        }
    }

    #endregion
}


